{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f874998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "if \"notebooks\" in os.getcwd():\n",
    "    sys.path.append([\"../src\"])\n",
    "from dataset import CastDefectDataset   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773782f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load YAML config\n",
    "with open(\"../src/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "\n",
    "CSV_TRAIN = os.path.abspath(os.path.join(\"..\", config[\"default\"][\"csv_train\"]))\n",
    "CSV_VALID = os.path.abspath(os.path.join(\"..\", config[\"default\"][\"csv_valid\"]))\n",
    "IMG_DIR_TRAIN = os.path.abspath(os.path.join(\"..\", config[\"default\"][\"img_dir_train\"]))\n",
    "IMG_DIR_VALID = os.path.abspath(os.path.join(\"..\", config[\"default\"][\"img_dir_valid\"]))\n",
    "SAVE_PATH = os.path.abspath(os.path.join(\"..\", config[\"default\"][\"save_path\"]))\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = config['default']['batch_size']\n",
    "IMG_SIZE = config[\"default\"][\"img_size\"]\n",
    "EPOCHS = config[\"default\"][\"epochs\"]\n",
    "LR = config[\"default\"][\"lr\"]\n",
    "PATIENCE = config[\"default\"][\"patience\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5c8d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. DATA PREPARATION\n",
    "# -------------------------------\n",
    "# Load CSVs\n",
    "df_train = pd.read_csv(CSV_TRAIN)\n",
    "df_train[\"label\"] = df_train[\"def_front\"]\n",
    "\n",
    "df_valid = pd.read_csv(CSV_VALID)\n",
    "df_valid[\"label\"] = df_valid[\"def_front\"]\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = CastDefectDataset(df_train, IMG_DIR_TRAIN, transform)\n",
    "val_dataset = CastDefectDataset(df_valid, IMG_DIR_VALID, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6abb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. MODEL SETUP\n",
    "# -------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. TRAINING LOOP\n",
    "# -------------------------------\n",
    "best_val_loss = float(\"inf\")\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ---- Training ----\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "        images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss, preds, targets = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Valid]\"):\n",
    "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds.extend((probs > 0.5).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    # ---- Metrics ----\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    prec = precision_score(targets, preds)\n",
    "    rec = recall_score(targets, preds)\n",
    "    f1 = f1_score(targets, preds)\n",
    "    auc = roc_auc_score(targets, preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f} | \"\n",
    "          f\"Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | \"\n",
    "          f\"F1: {f1:.4f} | AUC: {auc:.4f}\")\n",
    "\n",
    "    # ---- Early Stopping ----\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"‚úÖ Model improved, saved to {SAVE_PATH}\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"‚ö†Ô∏è No improvement ({patience_counter}/{PATIENCE} patience)\")\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"‚èπÔ∏è Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "# -------------------------------\n",
    "# 6. FINAL EVALUATION\n",
    "# -------------------------------\n",
    "print(\"\\nüìä Final Model Evaluation\")\n",
    "cm = confusion_matrix(targets, preds)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"OK\", \"Defected\"],\n",
    "            yticklabels=[\"OK\", \"Defected\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "# Ensure reports/ directory exists\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "\n",
    "# Save plot\n",
    "plot_path = os.path.join(\"reports\", \"confusion_matrix.png\")\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"‚úÖ Confusion matrix saved to {plot_path}\")\n",
    "\n",
    "# Show (only works if GUI / notebook is available)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
